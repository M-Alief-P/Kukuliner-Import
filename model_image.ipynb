{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NncM5nbxRDw",
        "outputId": "518e069c-552f-4f7c-a1b5-0c24fda57c66"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders"
      ],
      "metadata": {
        "id": "6YtqnCnHxzss"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan Google Colab untuk mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVp-ah28x94g",
        "outputId": "0ee0cccb-74c1-459c-e036-265db81570f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = '/content/drive/MyDrive/dataset'\n",
        "output_folder = '/content/drive/MyDrive/capstone'"
      ],
      "metadata": {
        "id": "2R84DzOjx5YM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitfolders.ratio(input_folder, output=output_folder, seed=38, ratio=(.7, .3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRDXyATE0cAu",
        "outputId": "77d9d6f9-72b6-4b2b-b532-35efec879b64"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 2145 files [05:53,  6.07 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N1OhYE2SCZc",
        "outputId": "7761c56c-005d-4e77-b143-3010ef2235ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Baso', 'Dadar Gulung', 'Gudeg', 'Kerak Telor', 'Nasi Goreng', 'Nasi Kuning', 'Nasi Pecel', 'Peuyeum', 'Putu Ayu', 'Rawon', 'Serabi', 'Soto Lamongan', 'Tahu Sumedang', 'Telur Balado']\n",
            "['Baso', 'Dadar Gulung', 'Gudeg', 'Kerak Telor', 'Nasi Goreng', 'Nasi Kuning', 'Nasi Pecel', 'Peuyeum', 'Putu Ayu', 'Rawon', 'Serabi', 'Soto Lamongan', 'Tahu Sumedang', 'Telur Balado']\n",
            "Found 1493 images belonging to 14 classes.\n",
            "Found 652 images belonging to 14 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Epoch 1/100\n",
            "46/46 [==============================] - 53s 1s/step - loss: 2.4790 - accuracy: 0.2724 - val_loss: 1.6917 - val_accuracy: 0.5188\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 47s 1s/step - loss: 1.8221 - accuracy: 0.4559 - val_loss: 1.3317 - val_accuracy: 0.6156\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 41s 890ms/step - loss: 1.5321 - accuracy: 0.5311 - val_loss: 1.0915 - val_accuracy: 0.6859\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 38s 835ms/step - loss: 1.2939 - accuracy: 0.5962 - val_loss: 1.0000 - val_accuracy: 0.7016\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 41s 890ms/step - loss: 1.1415 - accuracy: 0.6482 - val_loss: 0.8619 - val_accuracy: 0.7375\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 38s 830ms/step - loss: 1.0089 - accuracy: 0.6961 - val_loss: 0.7635 - val_accuracy: 0.7797\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 38s 820ms/step - loss: 0.9367 - accuracy: 0.7070 - val_loss: 0.7188 - val_accuracy: 0.7734\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 40s 869ms/step - loss: 0.8524 - accuracy: 0.7269 - val_loss: 0.6166 - val_accuracy: 0.8234\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.7939 - accuracy: 0.7467 - val_loss: 0.6042 - val_accuracy: 0.8188\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 40s 876ms/step - loss: 0.7344 - accuracy: 0.7687 - val_loss: 0.5493 - val_accuracy: 0.8359\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 38s 829ms/step - loss: 0.7350 - accuracy: 0.7714 - val_loss: 0.5699 - val_accuracy: 0.8219\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 40s 873ms/step - loss: 0.6748 - accuracy: 0.7851 - val_loss: 0.5235 - val_accuracy: 0.8297\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.6218 - accuracy: 0.8084 - val_loss: 0.4925 - val_accuracy: 0.8609\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 40s 871ms/step - loss: 0.6183 - accuracy: 0.8070 - val_loss: 0.4839 - val_accuracy: 0.8625\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 38s 830ms/step - loss: 0.5666 - accuracy: 0.8145 - val_loss: 0.4404 - val_accuracy: 0.8703\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 40s 878ms/step - loss: 0.4957 - accuracy: 0.8446 - val_loss: 0.4942 - val_accuracy: 0.8391\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.5596 - accuracy: 0.8207 - val_loss: 0.4429 - val_accuracy: 0.8656\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 40s 875ms/step - loss: 0.5276 - accuracy: 0.8364 - val_loss: 0.4302 - val_accuracy: 0.8797\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.4920 - accuracy: 0.8439 - val_loss: 0.4252 - val_accuracy: 0.8656\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 41s 885ms/step - loss: 0.4706 - accuracy: 0.8508 - val_loss: 0.3708 - val_accuracy: 0.8891\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.4576 - accuracy: 0.8590 - val_loss: 0.4047 - val_accuracy: 0.8797\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 40s 874ms/step - loss: 0.4932 - accuracy: 0.8480 - val_loss: 0.3763 - val_accuracy: 0.8781\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 38s 828ms/step - loss: 0.4391 - accuracy: 0.8652 - val_loss: 0.3934 - val_accuracy: 0.8953\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 40s 857ms/step - loss: 0.4077 - accuracy: 0.8624 - val_loss: 0.3958 - val_accuracy: 0.8734\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.3840 - accuracy: 0.8775 - val_loss: 0.3432 - val_accuracy: 0.8828\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.4121 - accuracy: 0.8693 - val_loss: 0.3643 - val_accuracy: 0.8891\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 40s 882ms/step - loss: 0.4038 - accuracy: 0.8795 - val_loss: 0.3644 - val_accuracy: 0.8953\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 38s 822ms/step - loss: 0.3838 - accuracy: 0.8665 - val_loss: 0.3507 - val_accuracy: 0.8953\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 41s 889ms/step - loss: 0.3589 - accuracy: 0.8809 - val_loss: 0.3368 - val_accuracy: 0.8953\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 46s 1s/step - loss: 0.3628 - accuracy: 0.8830 - val_loss: 0.3448 - val_accuracy: 0.8969\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 38s 832ms/step - loss: 0.3623 - accuracy: 0.8795 - val_loss: 0.3740 - val_accuracy: 0.8844\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 40s 877ms/step - loss: 0.3378 - accuracy: 0.8946 - val_loss: 0.3431 - val_accuracy: 0.8844\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.3346 - accuracy: 0.8899 - val_loss: 0.3436 - val_accuracy: 0.8984\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 48s 1s/step - loss: 0.3141 - accuracy: 0.9049 - val_loss: 0.3205 - val_accuracy: 0.8984\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 41s 886ms/step - loss: 0.3257 - accuracy: 0.8966 - val_loss: 0.3062 - val_accuracy: 0.9031\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.3109 - accuracy: 0.8966 - val_loss: 0.3325 - val_accuracy: 0.9031\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 42s 912ms/step - loss: 0.2998 - accuracy: 0.9035 - val_loss: 0.2971 - val_accuracy: 0.9156\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.2857 - accuracy: 0.9055 - val_loss: 0.3125 - val_accuracy: 0.9016\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 41s 894ms/step - loss: 0.2776 - accuracy: 0.9138 - val_loss: 0.3294 - val_accuracy: 0.8922\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.2730 - accuracy: 0.9083 - val_loss: 0.3082 - val_accuracy: 0.8984\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 41s 891ms/step - loss: 0.2844 - accuracy: 0.9021 - val_loss: 0.3356 - val_accuracy: 0.8875\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 48s 1s/step - loss: 0.2975 - accuracy: 0.9014 - val_loss: 0.3105 - val_accuracy: 0.9031\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 45s 992ms/step - loss: 0.2827 - accuracy: 0.9117 - val_loss: 0.3069 - val_accuracy: 0.9000\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 40s 884ms/step - loss: 0.2766 - accuracy: 0.9206 - val_loss: 0.2798 - val_accuracy: 0.9172\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 48s 1s/step - loss: 0.2645 - accuracy: 0.9199 - val_loss: 0.3114 - val_accuracy: 0.9078\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.2798 - accuracy: 0.9069 - val_loss: 0.3054 - val_accuracy: 0.9016\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 39s 856ms/step - loss: 0.2654 - accuracy: 0.9090 - val_loss: 0.3397 - val_accuracy: 0.8969\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 39s 851ms/step - loss: 0.2590 - accuracy: 0.9213 - val_loss: 0.2740 - val_accuracy: 0.9141\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.2552 - accuracy: 0.9110 - val_loss: 0.3222 - val_accuracy: 0.8969\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 48s 1s/step - loss: 0.2501 - accuracy: 0.9240 - val_loss: 0.3003 - val_accuracy: 0.9094\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 38s 831ms/step - loss: 0.2342 - accuracy: 0.9247 - val_loss: 0.3177 - val_accuracy: 0.8969\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 41s 880ms/step - loss: 0.2466 - accuracy: 0.9138 - val_loss: 0.2904 - val_accuracy: 0.9047\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 41s 890ms/step - loss: 0.1949 - accuracy: 0.9411 - val_loss: 0.3129 - val_accuracy: 0.8922\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 38s 829ms/step - loss: 0.2107 - accuracy: 0.9316 - val_loss: 0.3330 - val_accuracy: 0.9016\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 40s 878ms/step - loss: 0.2695 - accuracy: 0.9110 - val_loss: 0.3058 - val_accuracy: 0.9016\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.2145 - accuracy: 0.9302 - val_loss: 0.2791 - val_accuracy: 0.9187\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 44s 936ms/step - loss: 0.2075 - accuracy: 0.9281 - val_loss: 0.2979 - val_accuracy: 0.9094\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 0.2110 - accuracy: 0.9329 - val_loss: 0.2933 - val_accuracy: 0.9062\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Menentukan direktori data\n",
        "data_dir = \"/content/drive/MyDrive/capstone\"\n",
        "train_data_dir = os.path.join(data_dir, 'train')\n",
        "validation_data_dir = os.path.join(data_dir, 'val')\n",
        "\n",
        "# Mendapatkan daftar kategori (kelas) makanan\n",
        "train_directories = sorted(os.listdir(train_data_dir), key=str.lower)\n",
        "validation_directories = sorted(os.listdir(validation_data_dir), key=str.lower)\n",
        "\n",
        "print(train_directories)\n",
        "print(validation_directories)\n",
        "\n",
        "# Augmentasi Data\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Menentukan jumlah kelas\n",
        "num_classes = len(train_directories)\n",
        "\n",
        "# Transfer Learning dengan MobileNetV2\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# Membekukan lapisan di base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Menambahkan lapisan klasifikasi di atas base model\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "# Mengompilasi model\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callback untuk early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Melatih model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(train_generator)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "# Save the entire model\n",
        "model_save_path = 'my_model.h5'\n",
        "model.save(model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEW3NM59dES4",
        "outputId": "124b5fe9-26b1-46ad-cdb7-24890247ca9b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 29s 607ms/step - loss: 0.1312 - accuracy: 0.9658\n",
            "Accuracy: 0.9658405780792236\n",
            "21/21 [==============================] - 13s 593ms/step - loss: 0.2886 - accuracy: 0.9003\n",
            "Validation Accuracy: 0.900306761264801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model to TensorFlow Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "tflite_model_path = 'my_model.tflite'\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU-2K6HpgshQ",
        "outputId": "9fb78363-22ad-4c86-92f0-21b3e94b55f9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`mobilenetv2_1.00_128_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_128_input`.\n",
            "WARNING:absl:`mobilenetv2_1.00_128_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_128_input`.\n",
            "WARNING:absl:`mobilenetv2_1.00_128_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_128_input`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat file label.txt\n",
        "label_content = \"\"\"\n",
        "Bakso\n",
        "Dadar Gulung\n",
        "Gudeg\n",
        "Kerak Telor\n",
        "Nasi Goreng\n",
        "Nasi Kuning\n",
        "Nasi Pecel\n",
        "Peuyeum\n",
        "Putu Ayu\n",
        "Rawon\n",
        "Serabi\n",
        "Soto Lamongan\n",
        "Tahu Sumedang\n",
        "Telur Balado\n",
        "\"\"\"\n",
        "with open('label.txt', 'w') as f:\n",
        "    f.write(label_content.strip())"
      ],
      "metadata": {
        "id": "183aSUyIenM8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pastikan Anda menginstal tflite-support\n",
        "!pip install tflite-support"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A1XU0Y9fTRD",
        "outputId": "11ae9256-24ab-4eec-823e-5aafe9817d1e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tflite-support in /usr/local/lib/python3.10/dist-packages (0.4.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support) (1.25.2)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support) (24.3.25)\n",
            "Requirement already satisfied: protobuf<4,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support) (3.20.3)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from tflite-support) (0.4.7)\n",
            "Requirement already satisfied: pybind11>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from tflite-support) (2.12.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->tflite-support) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite-support) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tflite_support.metadata_writers import image_classifier\n",
        "from tflite_support.metadata_writers import writer_utils\n",
        "\n",
        "# Path to the model file\n",
        "model_path = \"my_model.tflite\"\n",
        "\n",
        "# Path to the label file\n",
        "label_file_path = \"label.txt\"\n",
        "\n",
        "# Path to save the new model with metadata\n",
        "model_with_metadata_path = \"/content/drive/MyDrive/model_with_metadata.tflite\"\n",
        "\n",
        "# Memuat file model\n",
        "model_content = writer_utils.load_file(model_path)\n",
        "\n",
        "# Membuat writer untuk menambahkan metadata\n",
        "writer = image_classifier.MetadataWriter.create_for_inference(\n",
        "    model_content,\n",
        "    input_norm_mean=[127.5],\n",
        "    input_norm_std=[127.5],\n",
        "    label_file_paths=[label_file_path]\n",
        ")\n",
        "\n",
        "# Menyimpan model baru dengan metadata\n",
        "writer_utils.save_file(writer.populate(), model_with_metadata_path)\n",
        "\n",
        "# Mengunduh file model baru\n",
        "from google.colab import files\n",
        "files.download(model_with_metadata_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "S6LkaAyyflV4",
        "outputId": "23ea4f53-b0be-4931-c926-33c2e1849671"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bb1881a3-7eb7-4c05-9dee-e5f4b4963a56\", \"model_with_metadata.tflite\", 10193790)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Load TFLite model and allocate tensors\n",
        "interpreter = tf.lite.Interpreter(model_path='model_with_metadata (3).tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Function to preprocess the image\n",
        "def preprocess_image(image_path):\n",
        "    img = Image.open(image_path).resize((128, 128))  # Adjust the size according to your model\n",
        "    img = np.array(img).astype(np.float32)\n",
        "    img = (img / 127.5) - 1  # Normalize image to [-1, 1]\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "    return img\n",
        "\n",
        "# Function to postprocess the output\n",
        "def postprocess_output(output_data):\n",
        "    probabilities = tf.nn.softmax(output_data[0])  # Apply softmax to get probabilities\n",
        "    class_index = np.argmax(probabilities)  # Get the index of the highest probability\n",
        "    return class_index, probabilities[class_index]\n",
        "\n",
        "# Load label file\n",
        "label_file_path = 'label.txt'\n",
        "with open(label_file_path, 'r') as f:\n",
        "    labels = f.read().splitlines()\n",
        "\n",
        "# Path to the test image\n",
        "test_image_path = 'Screenshot 2024-06-16 200719.jpg'\n",
        "\n",
        "# Preprocess the image\n",
        "input_data = preprocess_image(test_image_path)\n",
        "\n",
        "# Set the input tensor\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "# Run inference\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the output tensor\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "# Postprocess the output to get the class index and its probability\n",
        "class_index, class_probability = postprocess_output(output_data)\n",
        "food_name = labels[class_index]\n",
        "\n",
        "\n",
        "print(f'The model predicts this image is: {food_name}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUVrQrichcga",
        "outputId": "7a762af6-9f18-467f-f98f-3a9b4962e817"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model predicts this image is: Rawon\n"
          ]
        }
      ]
    }
  ]
}